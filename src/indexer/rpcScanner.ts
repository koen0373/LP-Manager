/**
 * RPC Scanner with Adaptive Retry & Concurrency
 * 
 * Fetches blockchain logs in chunks with exponential backoff and adaptive concurrency control.
 */

import { createPublicClient, http, Log, type PublicClient } from 'viem';
import { flare } from 'viem/chains';
import pLimit from 'p-limit';
import { indexerConfig } from '../../indexer.config';
import { getEventTopics } from './abis';

export interface ScanOptions {
  fromBlock: number;
  toBlock: number;
  contractAddress: string;
  tokenIds?: string[]; // Optional: filter by specific tokenIds
  dryRun?: boolean;
  topics?: string[];
}

export interface ScanResult {
  logs: Log[];
  scannedBlocks: number;
  elapsedMs: number;
  retriesUsed: number;
}

export class RpcScanner {
  private client: PublicClient;
  private limit: ReturnType<typeof pLimit>;
  private consecutiveFailures = 0;
  private consecutiveSuccesses = 0;
  private currentConcurrency: number;

  constructor() {
    this.client = createPublicClient({
      chain: flare,
      transport: http(indexerConfig.rpc.url, {
        timeout: indexerConfig.rpc.requestTimeout,
      }),
    });

    this.currentConcurrency = indexerConfig.rpc.maxConcurrency;
    this.limit = pLimit(this.currentConcurrency);
  }

  /**
   * Scan a block range and return all matching logs
   */
  async scan(options: ScanOptions): Promise<ScanResult> {
    const startTime = Date.now();
    const { fromBlock, toBlock, contractAddress, tokenIds, dryRun, topics } = options;

    if (fromBlock > toBlock) {
      throw new Error(`Invalid range: fromBlock (${fromBlock}) > toBlock (${toBlock})`);
    }

    // Calculate chunk ranges
    const ranges = this.createChunkRanges(fromBlock, toBlock, indexerConfig.rpc.batchSize);
    console.log(`[RPC] Scanning ${fromBlock}â†’${toBlock} (${ranges.length} chunks, concurrency=${this.currentConcurrency})`);

    // Fetch logs in parallel with concurrency limit
    const results = await Promise.all(
      ranges.map((range) =>
        this.limit(() =>
          this.fetchLogsWithRetry(range, contractAddress, tokenIds, dryRun, topics)
        )
      )
    );

    // Merge all logs
    const allLogs = results.flatMap((r) => r.logs);
    const totalRetries = results.reduce((sum, r) => sum + r.retriesUsed, 0);

    const elapsedMs = Date.now() - startTime;
    const scannedBlocks = toBlock - fromBlock + 1;

    console.log(
      `[RPC] âœ“ Scanned ${scannedBlocks} blocks â†’ ${allLogs.length} logs (${Math.round(scannedBlocks / (elapsedMs / 1000))}/s, ${totalRetries} retries)`
    );

    return {
      logs: allLogs,
      scannedBlocks,
      elapsedMs,
      retriesUsed: totalRetries,
    };
  }

  /**
   * Fetch logs for a single chunk with exponential backoff retry
   */
  private async fetchLogsWithRetry(
    range: { from: number; to: number },
    contractAddress: string,
    tokenIds?: string[],
    dryRun?: boolean,
    topics?: string[]
  ): Promise<{ logs: Log[]; retriesUsed: number }> {
    const { from, to } = range;
    let attempt = 0;
    let delay = indexerConfig.retry.initialDelayMs;

    while (attempt < indexerConfig.retry.maxAttempts) {
      try {
        // Get event topics for filtering
        const eventTopics = topics ?? getEventTopics(indexerConfig.events);

        let logs: Log[] = [];
        let fetchedWithTopics = false;

        if (eventTopics.length > 0) {
          try {
            logs = await this.client.getLogs({
              address: contractAddress as `0x${string}`,
              fromBlock: BigInt(from),
              toBlock: BigInt(to),
              topics: [eventTopics.map((topic) => topic as `0x${string}`)],
            });
            fetchedWithTopics = true;
          } catch (error) {
            if (process.env.POOL_DEBUG === '1') {
              console.warn(
                `[RpcScanner] topics fetch failed ${from}â†’${to} (${eventTopics.length} topics): ${(error as Error).message}`
              );
            }
          }
        }

        if (!fetchedWithTopics) {
          logs = await this.client.getLogs({
            address: contractAddress as `0x${string}`,
            fromBlock: BigInt(from),
            toBlock: BigInt(to),
          });
        }

        let filteredLogs = logs;
        if (eventTopics.length > 0) {
          const topicSet = new Set(eventTopics.map((t) => t.toLowerCase()));
          filteredLogs = filteredLogs.filter(
            (log) => log.topics[0] && topicSet.has((log.topics[0] as string).toLowerCase())
          );
        }

        // Filter by tokenId if specified (post-filter for events that index tokenId in topics[1])
        if (tokenIds && tokenIds.length > 0) {
          filteredLogs = filteredLogs.filter((log) => {
            // tokenId is in topics[1] for IncreaseLiquidity, DecreaseLiquidity, Collect, Transfer
            const tokenIdHex = log.topics[1];
            if (!tokenIdHex) return false;
            const tokenId = BigInt(tokenIdHex).toString();
            return tokenIds.includes(tokenId);
          });
        }

        if (!dryRun && filteredLogs.length > 0) {
          console.log(`[RPC] âœ“ ${from}â†’${to} (${filteredLogs.length} logs)`);
        }

        // Track success
        this.onSuccess();

        return { logs: filteredLogs, retriesUsed: attempt };
      } catch (error) {
        attempt++;
        this.onFailure();

        const isLastAttempt = attempt >= indexerConfig.retry.maxAttempts;

        if (isLastAttempt) {
          console.error(`[RPC] âœ— ${from}â†’${to} failed after ${attempt} attempts:`, error);
          throw error;
        }

        console.warn(
          `[RPC] âš  ${from}â†’${to} failed (attempt ${attempt}/${indexerConfig.retry.maxAttempts}), retrying in ${delay}ms...`
        );

        await this.sleep(delay);
        delay = Math.min(delay * indexerConfig.retry.backoffMultiplier, indexerConfig.retry.maxDelayMs);
      }
    }

    throw new Error(`Unreachable: max retries exceeded for ${from}â†’${to}`);
  }

  /**
   * Get latest block number from RPC
   */
  async getLatestBlock(): Promise<number> {
    const blockNumber = await this.client.getBlockNumber();
    return Number(blockNumber);
  }

  /**
   * Get block timestamp
   */
  async getBlockTimestamp(blockNumber: number): Promise<number> {
    const block = await this.client.getBlock({ blockNumber: BigInt(blockNumber) });
    return Number(block.timestamp);
  }

  /**
   * Split block range into chunks
   */
  private createChunkRanges(from: number, to: number, chunkSize: number): Array<{ from: number; to: number }> {
    const ranges: Array<{ from: number; to: number }> = [];
    let current = from;

    while (current <= to) {
      const end = Math.min(current + chunkSize - 1, to);
      ranges.push({ from: current, to: end });
      current = end + 1;
    }

    return ranges;
  }

  /**
   * Adaptive concurrency: reduce on failures, increase on successes
   */
  private onFailure() {
    this.consecutiveFailures++;
    this.consecutiveSuccesses = 0;

    if (this.consecutiveFailures >= indexerConfig.retry.failureThreshold) {
      const newConcurrency = Math.max(this.currentConcurrency - 1, indexerConfig.rpc.minConcurrency);
      if (newConcurrency !== this.currentConcurrency) {
        console.log(`[RPC] ðŸ”» Reducing concurrency: ${this.currentConcurrency} â†’ ${newConcurrency}`);
        this.currentConcurrency = newConcurrency;
        this.limit = pLimit(newConcurrency);
      }
      this.consecutiveFailures = 0;
    }
  }

  private onSuccess() {
    this.consecutiveSuccesses++;
    this.consecutiveFailures = 0;

    if (this.consecutiveSuccesses >= indexerConfig.retry.successThreshold) {
      const newConcurrency = Math.min(this.currentConcurrency + 1, indexerConfig.rpc.maxConcurrency);
      if (newConcurrency !== this.currentConcurrency) {
        console.log(`[RPC] ðŸ”º Increasing concurrency: ${this.currentConcurrency} â†’ ${newConcurrency}`);
        this.currentConcurrency = newConcurrency;
        this.limit = pLimit(newConcurrency);
      }
      this.consecutiveSuccesses = 0;
    }
  }

  private sleep(ms: number): Promise<void> {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }
}
